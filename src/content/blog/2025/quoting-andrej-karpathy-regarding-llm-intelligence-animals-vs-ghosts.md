---
title: |
    Quoting Andrej Karpathy regarding LLM intelligence Animals vs Ghosts
pubDate: 2025-09-12
description: |
    Quoting Andrej Karpathy regarding LLM intelligence Animals vs Ghosts
tags: ['ai', 'software-developer', 'project-management']
---
[Quoting Andrej Karpathy regarding LLM intelligence Animals vs Ghosts](https://x.com/karpathy/status/1979644538185752935)

> In my mind, animals are not an example of this at all - they are prepackaged with a ton of
> intelligence by evolution and the learning they do is quite minimal overall (example: Zebra at
> birth). Putting our engineering hats on, we're not going to redo evolution. But with LLMs we have
> stumbled by an alternative approach to "prepackage" a ton of intelligence in a neural network - not
> by evolution, but by predicting the next token over the internet. This approach leads to a different
> kind of entity in the intelligence space. Distinct from animals, more like ghosts or spirits. But we
> can (and should) make them more animal like over time and in some ways that's what a lot of frontier
> work is about.

That’s beautifully said. It paints a vivid picture of how LLM intelligence differs from biological
intelligence. By training on the collective content of the internet, these models become a form of
us, our past selves, our ghosts. We recognize an intelligence in them, but it’s a mistake to equate
it with human or animal intelligence.

Is the current intelligence enough for AGI? Will the next AI winter come from trying to make models
more like animals? Is that even a wise path to pursue?

I don’t think today’s intelligence is sufficient for true AGI. As Karpathy pointed out, it’s a
fundamentally different kind of intelligence. I don’t see how this architecture evolves into
something truly general. It can get closer, sure, but there will always be holes needing to be
plugged. This will bring forth the next AI winter, until the next breakthrough is discovered and our
capabilities reach the next level.

Still, I’m uneasy about that pursuit. There’s already so much potential in what we have now. Entire
industries and creative fields haven’t even begun to fully explore it. And as a society, we’re
not prepared for the intelligence we already face. However, it is in our nature to always be
progressing. Perhaps by the time the next breakthrough occurs, society will have adjusted to the
current level of intelligence, better preparing us us for the next level.

