---
title: |
  Our Role Using LLMs
pubDate: 2026-01-05
description: |
  A reflection on how our role with generative AI has shifted from prompt engineering to context engineering to teaching, and what that means for knowledge work.
tags: ['ai', 'llms', 'prompt-engineering', 'context-engineering', 'teaching', 'knowledge-work']
---
Over the last few years, our role in working with generative AI has been shifting. Each year, the work moves a little further away from "writing the perfect prompt" and a little closer to shaping how AI operates in real environments.

## 2024: Prompt Engineering

Our role was crafting prompts to draw out of AI the knowledge and behavior we desired.

But prompting isn't enough when the AI doesn't have the right information.

## 2025: Context Engineering

Our role was providing the AI with the context so that it had the relevant information for the task. This also provided guardrails, focusing it on the aspect of the desired task instead of straying into other areas. It was provided new abilities through tools, allowing it to gather its own context.

## 2026: Teaching

Once AI can retrieve context for itself, the next challenge becomes how it interprets and applies the information.

Our role will be in guiding the AI on the context it retrieves. We will need to provide correction when it applies information mistakenly, as a result of unawareness of the complete task, or oversight of pertinent information they are not referencing. It needs to be instructed on how to wield the great knowledge it has access to.

## AI and knowledge work

This describes a broader transition in knowledge work.

AI excels at knowledge work. However, knowledge work is not limited to performing a task. Currently, information about the work, what is needed, is spread out across many systems, channels, people, etc. It still takes humans to be knowledgeable about the higher goal and where to seek information to create a complete picture of what is needed, or pull out what is desired.

In my previous position I worked at a financial institution. The software development department did not build the primary systems. Instead it created systems to integrate these systems together, which allowed both employees and customers a view of this data and perform operations. This provided a distinct advantage to the institution, because information was not siloed.

Our relationship with AI seems to be following a similar model. AI excels at performing tasks, but it still requires human oversight to bring everything together, connect the systems, and draw out the information.

The progression from prompt engineering to context engineering to teaching is really a shift in where the human value sits: less in producing the output, and more in guiding how the output is produced.
